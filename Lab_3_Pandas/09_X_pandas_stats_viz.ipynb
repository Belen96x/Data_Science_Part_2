{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises \"Lecture 8: Exploratory Data Analysis and Visualisation\"\n",
    "\n",
    "In this session, we will compute statistics and visualizations on Wikipedia articles from 16 categories, namely: \n",
    "\n",
    "> Airports, Artists, Astronauts, Astronomical_objects, Building, City, Comics_characters, Companies, Foods, Monuments_and_memorials, Politicians, Sports_teams, Sportspeople, Transport, Universities_and_colleges, Written_communication.\n",
    "\n",
    "Data: wkp directory containing .txt files         \n",
    "Python libraries\n",
    "- [os](https://docs.python.org/3.8/library/os.html), for listdir() to list files in a directory \n",
    "- [glob](https://docs.python.org/3/library/glob.html), for listing files in a directory whose names match certain patterns\n",
    "- [re](https://docs.python.org/3.8/library/re.html), for regular expressions \n",
    "- pandas\n",
    "- spacy (or Stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE LIBRARIES\n",
    "\n",
    "import os \n",
    "import glob\n",
    "import re\n",
    "import pandas as pd \n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Regexp and loading text files into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** \n",
    "\n",
    "* Get the list of file names in the **wkp/** directory\n",
    "* Hint: You can use os.path.basename to help you\n",
    "* Use a regexp together with the list of categories (given above: 'Airports', 'Artists'....) to split each file name  into 'id' and 'category'. For example: \n",
    "\n",
    "> File Name: 'Monteverde_Angel_Monuments_and_memorials'\n",
    "\n",
    "is split into: \n",
    "\n",
    "> Id: 'Monteverde_Angel'\n",
    "\n",
    "> Category: 'Monuments_and_memorials'\n",
    "\n",
    "* store each processed filename in a list of lists. The list is of the form \n",
    "```[[File name, Id, Category], ...]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "[['Airports_of_Serbia_Airports', 'Airports'], ['Airport_authority_Airports', 'Airports'], ['Airport_bus_Airports', 'Airports'], ['Airport_check-in_Airports', 'Airports'], ['Airport_security_Airports', 'Airports'], ['Airspace_Airports', 'Airports'], ['Airspace_Transport', 'Transport'], ['Airway_beacon_Airports', 'Airports'], ['Airway_beacon_Transport', 'Transport'], ['Aisam-ul-Haq_Qureshi_career_statistics_Sportspeople', 'Sportspeople'], ['Aish_tamid_Monuments_and_memorials', 'Monuments_and_memorials'], ['Aita_Mari_Transport', 'Transport'], ['Aiwowo_Foods', 'Foods'], ['Ajilim├│jili_Foods', 'Foods'], ['Ajman_International_Airport_Airports', 'Airports'], ['Aj├¡_(sauce)_Foods', 'Foods'], ['Akabeko_Building', 'Building'], ['Akaflieg_Transport', 'Transport'], ['Akay_Artists', 'Artists'], ['Akie_Dagogo_Fubara_Transport', 'Transport'], ['Akira_Ry┼ì_Sportspeople', 'Sportspeople'], ['Akira_Toriyama_(ophthalmologist)_Universities_and_colleges', 'Universities_and_colleges'], ['Akkamma_Devi_Politicians', 'Politicians'], ['Akmal_Ikramov_Politicians', 'Politicians'], ['Akmyrat_Rejepow_Politicians', 'Politicians'], ['Akonnedi_Shrine_Monuments_and_memorials', 'Monuments_and_memorials'], ['Akperan_Orshi_Polytechnic,_Yandev_Universities_and_colleges', 'Universities_and_colleges'], ['Aksel_J├©rgensen_Artists', 'Artists'], ['Akshar_Deri_Monuments_and_memorials', 'Monuments_and_memorials'], ['Aksjeselskap_Companies', 'Companies'], ['Aktieselskab_Companies', 'Companies'], ['Akwila_Simpasa_Artists', 'Artists'], ['Al-Badeel_Written_communication', 'Written_communication'], ['Al-Bairaq_Universities_and_colleges', 'Universities_and_colleges'], ['Al-Haj_Suliman_Yari_Politicians', 'Politicians'], ['Al-Jamahir_Written_communication', 'Written_communication'], ['Al-Machriq_Universities_and_colleges', 'Universities_and_colleges'], ['Al-Madinah_College_of_Technology_Universities_and_colleges', 'Universities_and_colleges'], ['Al-Malayin_Written_communication', 'Written_communication'], ['Al-Qasemi_Academic_College_of_Education_Universities_and_colleges', 'Universities_and_colleges'], ['Al-Quds_College_Universities_and_colleges', 'Universities_and_colleges'], ['Al-Thawra_(Libya)_Written_communication', 'Written_communication'], ['Al-Tilmiz_Written_communication', 'Written_communication'], ['Al-Wasat_(Bahraini_newspaper)_Written_communication', 'Written_communication'], ['Alabama_Gang_Sportspeople', 'Sportspeople'], ['Aladin_Sky_Atlas_Astronomical_objects', 'Astronomical_objects'], ['Alan_Kurdi_(ship)_Transport', 'Transport'], ['Ala_Kheir_Artists', 'Artists'], ['Al_and_Ann_Stohlman_Artists', 'Artists'], ['Al_Anwa_Aviation_Transport', 'Transport'], ['Al_Arab_Written_communication', 'Written_communication'], ['Al_Fazl_(newspaper)_Written_communication', 'Written_communication'], ['Al_HaMishmar_Written_communication', 'Written_communication'], ['Al_Jazeera_bombing_memo_Companies', 'Companies'], ['Al_Jazeera_controversies_and_criticism_Companies', 'Companies'], ['Al_Jazeera_effect_Companies', 'Companies'], ['Al_Jazeera_International_Documentary_Film_Festival_Companies', 'Companies'], ['Al_Jazeera_Mubasher_Companies', 'Companies'], ['Al_Jazeera_Podcasts_Companies', 'Companies'], ['Al_Jazeera_Urdu_Companies', 'Companies'], ['Al_MacKenzie_Comics_characters', 'Comics_characters'], ['Al_Muharrir_Written_communication', 'Written_communication'], ['Al_ZaquraMonuments_and_memorials', 'Building'], ['Anti-shock_body_Building', 'Building'], ['Anti-shock_body_Transport', 'Transport'], ['Association_of_Space_Explorers_Astronauts', 'Astronauts'], ['Astrup_Rectory_Building', 'Building'], ['Atmospheric_theatre_City', 'City'], ['Attempted_assassination_of_Leonid_Brezhnev_Astronauts', 'Astronauts'], ['Buzz_Aldrin_Astronauts', 'Astronauts'], ['Cannonball_(Marvel_Comics)_Comics_characters', 'Comics_characters'], ['Cardiff_Roller_Collective_Sports_teams', 'Sports_teams'], ['Carniny_Amateur_&_Youth_F', 'Sports_teams'], ['Carrozza_(sandwich)_Foods', 'Foods'], ['Casper_the_Friendly_Ghost_filmography_Comics_characters', 'Comics_characters'], ['Caste_systems_in_Africa_City', 'City'], ['Chatin_Sarachi_Politicians', 'Politicians'], ['Cloghanmore_Monuments_and_memorials', 'Monuments_and_memorials'], ['Coat_of_arms_of_Leeds_Astronomical_objects', 'Astronomical_objects'], ['Courteen_association_Companies', 'Companies'], ['Donald_Pierce_Comics_characters', 'Comics_characters'], ['Downwash_Building', 'Building'], ['Elongated_Man_Comics_characters', 'Comics_characters'], ['Fractio_Panis_Monuments_and_memorials', 'Monuments_and_memorials'], ['Gnarrk_Comics_characters', 'Comics_characters'], ['Go!_You_Packers_Go!_Sports_teams', 'Sports_teams'], ['Goldthwait_Cup_Sports_teams', 'Sports_teams'], ['Gre-No-Li_Sportspeople', 'Sportspeople'], ['Hatem_Abdel_Latif_Transport', 'Transport'], ['Hn├║┼í┼Ña_City', 'City'], ['Hubble_search_for_transition_comets_Astronomical_objects', 'Astronomical_objects'], ['Indian_Packing_Company_Sports_teams', 'Sports_teams'], ['James_A', 'Astronauts'], ['Jim_McCrary_Artists', 'Artists'], ['Jim_Renacci_Sports_teams', 'Sports_teams'], ['Joe_Petagno_Artists', 'Artists'], ['John_Akii-Bua_Sportspeople', 'Sportspeople'], ['John_M', 'Astronauts'], ['Josiah_Kibira_University_College_Universities_and_colleges', 'Universities_and_colleges'], ['Julius_Nyerere_University_of_Agriculture_Universities_and_colleges', 'Universities_and_colleges'], ['Juma_Mosque_in_Sheki_Monuments_and_memorials', 'Monuments_and_memorials'], ['Kapla_Building', 'Building'], ['Katterbach_Kaserne_Airports', 'Airports'], ['Khozh-Ahmed_Noukhayev_Politicians', 'Politicians'], ['Lance_Gibbs_Sportspeople', 'Sportspeople'], ['Leif_Elggren_Artists', 'Artists'], ['Lin_Dan_Sportspeople', 'Sportspeople'], ['Lori_Lemaris_Comics_characters', 'Comics_characters'], ['March_for_Jesus_City', 'City'], ['Mel_Sheppard_Sportspeople', 'Sportspeople'], ['Memphis_Air_Route_Traffic_Control_Center_Airports', 'Airports'], ['Merlon_Building', 'Building'], ['Messier_62_Astronomical_objects', 'Astronomical_objects'], ['Messier_85_Astronomical_objects', 'Astronomical_objects'], ['Metakaolin_Building', 'Building'], ['Miguel_├üngel_Mart├¡n_Bordera_Artists', 'Artists'], ['Monteverde_Angel_Monuments_and_memorials', 'Monuments_and_memorials'], ['M├ñntt├ñ-Vilppula_City', 'City'], ['Natural_burial_Monuments_and_memorials', 'Monuments_and_memorials'], ['NGC_2257_Astronomical_objects', 'Astronomical_objects'], ['NGC_2452_Astronomical_objects', 'Astronomical_objects'], ['NGC_4314_Astronomical_objects', 'Astronomical_objects'], ['NGC_5824_Astronomical_objects', 'Astronomical_objects'], ['Nie_Haisheng_Astronauts', 'Astronauts'], ['Olga_Krishtop_Sportspeople', 'Sportspeople'], ['Omer_Vrioni_Politicians', 'Politicians'], ['Paomo_Foods', 'Foods'], ['Pastiera_Foods', 'Foods'], ['Piano_music_of_Gabriel_Faur├®_Monuments_and_memorials', 'Monuments_and_memorials'], ['Pitch-up_Building', 'Building'], ['Pitch-up_Transport', 'Transport'], ['Relocation_of_professional_sports_teams_in_Australia_and_New_Zealand_Sports_teams', 'Sports_teams'], ['Relocation_of_professional_sports_teams_in_China_Sports_teams', 'Sports_teams'], ['Rocky_Mountain_Showdown_Sports_teams', 'Sports_teams'], ['Roman_cement_Building', 'Building'], ['Salahuddin_Quader_Chowdhury_Politicians', 'Politicians'], ['Sapphire_Stagg_Comics_characters', 'Comics_characters'], ['Saturnyne_Comics_characters', 'Comics_characters'], ['Savonlinna_City', 'City'], ['Shito_Foods', 'Foods'], ['Smi┼Öice_City', 'City'], ['St', 'Universities_and_colleges'], ['Steel-cut_oats_Foods', 'Foods'], ['Stein_2051_Astronomical_objects', 'Astronomical_objects'], ['Stephen_Frick_Astronauts', 'Astronauts'], ['Sugar_crust_Foods', 'Foods'], ['Surpass_Foods', 'Foods'], ['Tracy_Caldwell_Dyson_Astronauts', 'Astronauts'], ['Ulrich_Walter_Astronauts', 'Astronauts'], ['Under_Western_Stars_Politicians', 'Politicians'], ['UP_Fighting_Maroons_Volleyball_Team_Sports_teams', 'Sports_teams'], ['Uran_Butka_Politicians', 'Politicians'], ['Victor_Mancha_Comics_characters', 'Comics_characters'], ['Vidnava_City', 'City'], ['Vladimir_Dzhanibekov_Astronauts', 'Astronauts'], ['Votice_City', 'City'], ['Wetted_area_Building', 'Building'], ['William_Hogarth_Artists', 'Artists'], ['Wolfgang_Nordwig_Sportspeople', 'Sportspeople'], ['┼¢idlochovice_City', 'City']]\n"
     ]
    }
   ],
   "source": [
    "# Establish categories to track and track it into a regex format\n",
    "categories = [\n",
    "    'Airports', 'Artists', 'Astronauts', 'Astronomical_objects', \n",
    "    'Building', 'City', 'Comics_characters', 'Companies', 'Foods', \n",
    "    'Monuments_and_memorials', 'Politicians', 'Sports_teams', \n",
    "    'Sportspeople', 'Transport', 'Universities_and_colleges', \n",
    "    'Written_communication'\n",
    "]\n",
    "\n",
    "category_re = '|'.join(categories)\n",
    "\n",
    "# Extract the raw names of the files\n",
    "directory_path = r'C:\\Users\\belen\\Desktop\\Université de Lorraine\\Second semester\\Data_science_P2\\Lab_3_Pandas\\wkp'\n",
    "file_names = os.listdir(directory_path)\n",
    "\n",
    "# Process each file name\n",
    "names_list = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    # Get the base name\n",
    "    base_name = os.path.basename(file_name)\n",
    "\n",
    "    # Use regex to find the category in the file name\n",
    "    match = re.search(rf\"({category_re})\", base_name)\n",
    "    if match:\n",
    "        category = match.group(1)\n",
    "        # Remove the category part and extension to get the ID\n",
    "        file_id = re.sub(rf\"_{category}_|\\..*$\", \"\", base_name)\n",
    "        names_list.append([file_id, category])\n",
    "\n",
    "print(len(names_list))\n",
    "\n",
    "print(names_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** \n",
    "* Extract the content of the file (use **read()**, cf. python_basics cheatsheet))\n",
    "* Create a list of lists of the form (id, category, file_content). Save it to a variable \"data4pandas\" e.g., \n",
    "\n",
    "```\n",
    "data4pandas = [['Monteverde_Angel', 'Monuments_and_memorials', 'The Monteverde Angel or Angel of the Resurrect ....], ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontró archivo correspondiente para: ID = Al_ZaquraMonuments_and_memorials, Category = Building\n"
     ]
    }
   ],
   "source": [
    "# Method: read each file of the directory, and put the file into the same list \n",
    "\n",
    "data4pandas = []\n",
    "\n",
    "for item in names_list:\n",
    "    file_id, category = item  # Asegurándonos de desempacar correctamente\n",
    "    \n",
    "# Find the first filename that contains both the category and the ID; returns None if not found.\n",
    "    file_name = next((fn for fn in file_names if re.search(rf\"_{category}\", fn) and file_id in fn), None)\n",
    "    if not file_name:\n",
    "        print(f\"No se encontró archivo correspondiente para: ID = {file_id}, Category = {category}\")\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    \n",
    "    # Leer el contenido del archivo\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "    \n",
    "    data4pandas.append([file_id, category, file_content])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** \n",
    "\n",
    "* Create a dataframe from this list of lists (i.e. data4pandas). Remember to add the following column headers: 'id', 'category' and'text' (cf. pandas CS). Save this dataframe to a variable called 'df'. (it is a convention to name pandas dataframe starting with 'df')\n",
    "* inspect for yourself the first 10 and last 10 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   id           category  \\\n",
      "149  UP_Fighting_Maroons_Volleyball_Team_Sports_teams       Sports_teams   \n",
      "150                            Uran_Butka_Politicians        Politicians   \n",
      "151                   Victor_Mancha_Comics_characters  Comics_characters   \n",
      "152                                      Vidnava_City               City   \n",
      "153                   Vladimir_Dzhanibekov_Astronauts         Astronauts   \n",
      "154                                       Votice_City               City   \n",
      "155                              Wetted_area_Building           Building   \n",
      "156                           William_Hogarth_Artists            Artists   \n",
      "157                     Wolfgang_Nordwig_Sportspeople       Sportspeople   \n",
      "158                                ┼¢idlochovice_City               City   \n",
      "\n",
      "                                                  text  \n",
      "149  The University of the Philippines Fighting Mar...  \n",
      "150  Uran Butka (2 December 1938) is an Albanian wr...  \n",
      "151  Victor Mancha, also known as Victorious, is a ...  \n",
      "152  Vidnava (German: Weidenau, Polish: Widnawa) is...  \n",
      "153  Vladimir Aleksandrovich Dzhanibekov (Russian: ...  \n",
      "154  Votice (Czech pronunciation: [ˈvocɪtsɛ]; Germa...  \n",
      "155  The surface area that interacts with the worki...  \n",
      "156  William Hogarth  (; 10 November 1697 – 26 Octo...  \n",
      "157  Wolfgang Nordwig (born 27 August 1943) is a fo...  \n",
      "158  Židlochovice (Czech pronunciation: [ˈʒɪdloxovɪ...  \n"
     ]
    }
   ],
   "source": [
    "headers = ['id', 'category','text']\n",
    "\n",
    "df = pd.DataFrame(data4pandas, columns=headers)\n",
    "\n",
    "#print(df.head(10))\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the list of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** \n",
    "    \n",
    "- store the content of the **'category'** column into a string (cf. Pandas CS)\n",
    "- extract the set of unique categories from that string (cf. python basic CS)   \n",
    "You should find the following 16 categories\n",
    "\n",
    "```\n",
    "['Comics_characters', 'Astronauts', 'Transport', 'Artists', 'Written_communication', 'Sports_teams', 'Foods', 'Airports', 'Monuments_and_memorials', 'Politicians', 'Sportspeople', 'Building', 'Universities_and_colleges', 'Astronomical_objects', 'Companies', 'City']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Airports' 'Transport' 'Sportspeople' 'Monuments_and_memorials' 'Foods'\n",
      " 'Building' 'Artists' 'Universities_and_colleges' 'Politicians'\n",
      " 'Companies' 'Written_communication' 'Astronomical_objects'\n",
      " 'Comics_characters' 'Astronauts' 'City' 'Sports_teams']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "category_strings = df['category'].unique()\n",
    "print(category_strings)\n",
    "print(len(category_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the list of headers from the 'text' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** \n",
    "\n",
    "Hint: In the Wikipedia articles, headers are surrounded by \"==\" \n",
    "\n",
    "_*E.g., ==  Background == *_\n",
    "\n",
    "- Define a function called 'get_title' which extracts headers from a text (Use a regular expression)\n",
    "- Apply this function to the **'text'** column in your pandas data frame (use the pandas 'apply' method)\n",
    "- Store the result (the list of headers associated with each text in the frame) into a new pandas serie called 'headers'\n",
    "- Concatenate this series to your pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(df, column_name):\n",
    "    # Define the regex pattern to match headers surrounded by \"==\"\n",
    "    reg = r'==\\s*.*?\\s*=='\n",
    "    \n",
    "    # Apply the regex pattern to extract headers from each text in the specified column\n",
    "    df['headers'] = df[column_name].apply(lambda text: re.findall(reg, text))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airports_of_Serbia_Airports</td>\n",
       "      <td>Airports</td>\n",
       "      <td>Airports of Serbia (Serbian Cyrillic: Аеродром...</td>\n",
       "      <td>[== Airports ==, == References ==, == External...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airport_authority_Airports</td>\n",
       "      <td>Airports</td>\n",
       "      <td>An airport authority is an independent entity ...</td>\n",
       "      <td>[== Examples of airport authorities overseeing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airport_bus_Airports</td>\n",
       "      <td>Airports</td>\n",
       "      <td>An airport bus, or airport shuttle bus or airp...</td>\n",
       "      <td>[== On airport transfer ==, === Airside transf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airport_check-in_Airports</td>\n",
       "      <td>Airports</td>\n",
       "      <td>Airport check-in is the process whereby passen...</td>\n",
       "      <td>[== Types of check-in ==, === Destination or P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airport_security_Airports</td>\n",
       "      <td>Airports</td>\n",
       "      <td>Airport security refers to the techniques and ...</td>\n",
       "      <td>[== Description ==, == Airport enforcement aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Votice_City</td>\n",
       "      <td>City</td>\n",
       "      <td>Votice (Czech pronunciation: [ˈvocɪtsɛ]; Germa...</td>\n",
       "      <td>[== Administrative parts ==, == History ==, ==...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Wetted_area_Building</td>\n",
       "      <td>Building</td>\n",
       "      <td>The surface area that interacts with the worki...</td>\n",
       "      <td>[== References ==]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>William_Hogarth_Artists</td>\n",
       "      <td>Artists</td>\n",
       "      <td>William Hogarth  (; 10 November 1697 – 26 Octo...</td>\n",
       "      <td>[== Early life ==, == Career ==, === Early wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Wolfgang_Nordwig_Sportspeople</td>\n",
       "      <td>Sportspeople</td>\n",
       "      <td>Wolfgang Nordwig (born 27 August 1943) is a fo...</td>\n",
       "      <td>[== Athletic career ==, === World rankings ==,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>┼¢idlochovice_City</td>\n",
       "      <td>City</td>\n",
       "      <td>Židlochovice (Czech pronunciation: [ˈʒɪdloxovɪ...</td>\n",
       "      <td>[== Geography ==, == History ==, == Notable pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id      category  \\\n",
       "0      Airports_of_Serbia_Airports      Airports   \n",
       "1       Airport_authority_Airports      Airports   \n",
       "2             Airport_bus_Airports      Airports   \n",
       "3        Airport_check-in_Airports      Airports   \n",
       "4        Airport_security_Airports      Airports   \n",
       "..                             ...           ...   \n",
       "154                    Votice_City          City   \n",
       "155           Wetted_area_Building      Building   \n",
       "156        William_Hogarth_Artists       Artists   \n",
       "157  Wolfgang_Nordwig_Sportspeople  Sportspeople   \n",
       "158             ┼¢idlochovice_City          City   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Airports of Serbia (Serbian Cyrillic: Аеродром...   \n",
       "1    An airport authority is an independent entity ...   \n",
       "2    An airport bus, or airport shuttle bus or airp...   \n",
       "3    Airport check-in is the process whereby passen...   \n",
       "4    Airport security refers to the techniques and ...   \n",
       "..                                                 ...   \n",
       "154  Votice (Czech pronunciation: [ˈvocɪtsɛ]; Germa...   \n",
       "155  The surface area that interacts with the worki...   \n",
       "156  William Hogarth  (; 10 November 1697 – 26 Octo...   \n",
       "157  Wolfgang Nordwig (born 27 August 1943) is a fo...   \n",
       "158  Židlochovice (Czech pronunciation: [ˈʒɪdloxovɪ...   \n",
       "\n",
       "                                               headers  \n",
       "0    [== Airports ==, == References ==, == External...  \n",
       "1    [== Examples of airport authorities overseeing...  \n",
       "2    [== On airport transfer ==, === Airside transf...  \n",
       "3    [== Types of check-in ==, === Destination or P...  \n",
       "4    [== Description ==, == Airport enforcement aut...  \n",
       "..                                                 ...  \n",
       "154  [== Administrative parts ==, == History ==, ==...  \n",
       "155                                 [== References ==]  \n",
       "156  [== Early life ==, == Career ==, === Early wor...  \n",
       "157  [== Athletic career ==, === World rankings ==,...  \n",
       "158  [== Geography ==, == History ==, == Notable pe...  \n",
       "\n",
       "[159 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_title(df, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the vocabulary of each category\n",
    "\n",
    "For each category, we extract the corresponding vocabulary i.e., the list of tokens occurring in the corresponding texts (removing the duplicates)\n",
    "\n",
    "\n",
    "Optional: for each category\n",
    "- extract the list of headers\n",
    "- extract the noun and verbs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Exercise 6**\n",
    "\n",
    "* write a function called \"remove_underscores\" that takes a python string and replace all the '_' in it with a whitespace ' '. e.g. \"This_is_a_text\" becomes  \"This is a text\"\n",
    "* write a function called \"lowercase_string\" that takes a python string and lowercases it. e.g. \"This is a text\" becomes  \"this is a text\"\n",
    "* apply both of the remove_underscores and lowercase_string functions on the **'clean_text'** column of your dataframe. Save the output into a new column in your dataframe called 'clean_text' (consider using method chaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  remove_underscores():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7**\n",
    "\n",
    "- Define a function 'get_tokens' which, given a category, return its vocabulary (the list of tokens occurring in the texts of that category and after removing the duplicates). One way to do this is to:\n",
    "   - extract the category subframe i.e., all rows whose category column matches the input category\n",
    "   - create a string out of the text column of that subframe (use str.cat(sep=\" \"), cf. Pandas CS)\n",
    "   - run spacy or Stanza model on this string and extract the tokens from the resulting document (cf. Stanza or spacy CS)\n",
    "   - use python set method to remove duplicate tokens\n",
    "   - use python list method to convert the resulting set back into a list\n",
    "- Create a new dataframe with headers **'CATEGORY'** and **'VOCABULARY'** in which you store for each category the corresponding vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the differences in vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**\n",
    "\n",
    "- Use pandas 'apply' method to compute the size of each category's vocabulary (the number of tokens)\n",
    "- Add a **'VOCAB SIZE'** column to your the dataframe created in the previous exercise in which you input the size of the vocabulary for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9**\n",
    "\n",
    "Create a barplot showing the **VOCAB SIZE** of each **Category** (use e.g., pd.barh() method)\n",
    "\n",
    "- the y axis should show the categories\n",
    "- the x axis should show the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10**\n",
    "* create a scatter plot showing the correlation between the number of headers and each category\n",
    "* reminder: you have the headers stored in the pandas dataframe saved to the 'df' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
