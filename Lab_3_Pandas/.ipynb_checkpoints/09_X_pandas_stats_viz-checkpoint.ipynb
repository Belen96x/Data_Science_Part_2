{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises \"Lecture 8: Exploratory Data Analysis and Visualisation\"\n",
    "\n",
    "In this session, we will compute statistics and visualizations on Wikipedia articles from 16 categories, namely: \n",
    "\n",
    "> Airports, Artists, Astronauts, Astronomical_objects, Building, City, Comics_characters, Companies, Foods, Monuments_and_memorials, Politicians, Sports_teams, Sportspeople, Transport, Universities_and_colleges, Written_communication.\n",
    "\n",
    "Data: wkp directory containing .txt files         \n",
    "Python libraries\n",
    "- [os](https://docs.python.org/3.8/library/os.html), for listdir() to list files in a directory \n",
    "- [glob](https://docs.python.org/3/library/glob.html), for listing files in a directory whose names match certain patterns\n",
    "- [re](https://docs.python.org/3.8/library/re.html), for regular expressions \n",
    "- pandas\n",
    "- spacy (or Stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Regexp and loading text files into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** \n",
    "\n",
    "* Get the list of file names in the **wkp/** directory\n",
    "* Hint: You can use os.path.basename to help you\n",
    "* Use a regexp together with the list of categories (given above: 'Airports', 'Artists'....) to split each file name  into 'id' and 'category'. For example: \n",
    "\n",
    "> File Name: 'Monteverde_Angel_Monuments_and_memorials'\n",
    "\n",
    "is split into: \n",
    "\n",
    "> Id: 'Monteverde_Angel'\n",
    "\n",
    "> Category: 'Monuments_and_memorials'\n",
    "\n",
    "* store each processed filename in a list of lists. The list is of the form \n",
    "```[[File name, Id, Category], ...]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** \n",
    "* Extract the content of the file (use **read()**, cf. python_basics cheatsheet))\n",
    "* Create a list of lists of the form (id, category, file_content). Save it to a variable \"data4pandas\" e.g., \n",
    "\n",
    "```\n",
    "data4pandas = [['Monteverde_Angel', 'Monuments_and_memorials', 'The Monteverde Angel or Angel of the Resurrect ....], ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** \n",
    "\n",
    "* Create a dataframe from this list of lists (i.e. data4pandas). Remember to add the following column headers: 'id', 'category' and'text' (cf. pandas CS). Save this dataframe to a variable called 'df'. (it is a convention to name pandas dataframe starting with 'df')\n",
    "* inspect for yourself the first 10 and last 10 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the list of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** \n",
    "    \n",
    "- store the content of the **'category'** column into a string (cf. Pandas CS)\n",
    "- extract the set of unique categories from that string (cf. python basic CS)   \n",
    "You should find the following 16 categories\n",
    "\n",
    "```\n",
    "['Comics_characters', 'Astronauts', 'Transport', 'Artists', 'Written_communication', 'Sports_teams', 'Foods', 'Airports', 'Monuments_and_memorials', 'Politicians', 'Sportspeople', 'Building', 'Universities_and_colleges', 'Astronomical_objects', 'Companies', 'City']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the list of headers from the 'text' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** \n",
    "\n",
    "Hint: In the Wikipedia articles, headers are surrounded by \"==\" \n",
    "\n",
    "_*E.g., ==  Background == *_\n",
    "\n",
    "- Define a function called 'get_title' which extracts headers from a text (Use a regular expression)\n",
    "- Apply this function to the **'text'** column in your pandas data frame (use the pandas 'apply' method)\n",
    "- Store the result (the list of headers associated with each text in the frame) into a new pandas serie called 'headers'\n",
    "- Concatenate this series to your pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the vocabulary of each category\n",
    "\n",
    "For each category, we extract the corresponding vocabulary i.e., the list of tokens occurring in the corresponding texts (removing the duplicates)\n",
    "\n",
    "\n",
    "Optional: for each category\n",
    "- extract the list of headers\n",
    "- extract the noun and verbs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Exercise 6**\n",
    "\n",
    "* write a function called \"remove_underscores\" that takes a python string and replace all the '_' in it with a whitespace ' '. e.g. \"This_is_a_text\" becomes  \"This is a text\"\n",
    "* write a function called \"lowercase_string\" that takes a python string and lowercases it. e.g. \"This is a text\" becomes  \"this is a text\"\n",
    "* apply both of the remove_underscores and lowercase_string functions on the **'clean_text'** column of your dataframe. Save the output into a new column in your dataframe called 'clean_text' (consider using method chaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7**\n",
    "\n",
    "- Define a function 'get_tokens' which, given a category, return its vocabulary (the list of tokens occurring in the texts of that category and after removing the duplicates). One way to do this is to:\n",
    "   - extract the category subframe i.e., all rows whose category column matches the input category\n",
    "   - create a string out of the text column of that subframe (use str.cat(sep=\" \"), cf. Pandas CS)\n",
    "   - run spacy or Stanza model on this string and extract the tokens from the resulting document (cf. Stanza or spacy CS)\n",
    "   - use python set method to remove duplicate tokens\n",
    "   - use python list method to convert the resulting set back into a list\n",
    "- Create a new dataframe with headers **'CATEGORY'** and **'VOCABULARY'** in which you store for each category the corresponding vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the differences in vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**\n",
    "\n",
    "- Use pandas 'apply' method to compute the size of each category's vocabulary (the number of tokens)\n",
    "- Add a **'VOCAB SIZE'** column to your the dataframe created in the previous exercise in which you input the size of the vocabulary for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9**\n",
    "\n",
    "Create a barplot showing the **VOCAB SIZE** of each **Category** (use e.g., pd.barh() method)\n",
    "\n",
    "- the y axis should show the categories\n",
    "- the x axis should show the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10**\n",
    "* create a scatter plot showing the correlation between the number of headers and each category\n",
    "* reminder: you have the headers stored in the pandas dataframe saved to the 'df' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
