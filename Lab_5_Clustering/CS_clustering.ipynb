{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading files from a directory into a panda dataframe**\n",
    "\n",
    "* the  [load_files](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html) takes as input a directory in which the immediate subdirectories are category names for the text files they contain \n",
    "\n",
    "```\n",
    "DIR/\n",
    " category_1/\n",
    "    file_1.txt file_2.txt … file_42.txt\n",
    " category_2/\n",
    "    file_43.txt file_44.txt …\n",
    "```\n",
    "\n",
    "* the load_files method from sklearn \n",
    "recursively uploads all files in a directory and return a dictionary object with attributes:\n",
    "   - \"data\" whose value is the text content of the input files and \n",
    "   - \"target_names\" whose value is the names of the subdirectory containing the text files. \n",
    "* the code below uses this method to extract the content and categories of the text files contained in the ../data/bbc/ directory and to store them into a pandas frame with headers 'text' and 'label' respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business  entertainment  politics  README.TXT  sport  tech\r\n"
     ]
    }
   ],
   "source": [
    "!ls bbc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tate &amp; Lyle boss bags top award\\n\\nTate &amp; Lyle...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo 2 sells five million copies\\n\\nMicrosoft ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSPs hear renewed climate warning\\n\\nClimate c...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pavey focuses on indoor success\\n\\nJo Pavey wi...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tories reject rethink on axed MP\\n\\nSacked MP ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          label\n",
       "0  Tate & Lyle boss bags top award\\n\\nTate & Lyle...       business\n",
       "1  Halo 2 sells five million copies\\n\\nMicrosoft ...  entertainment\n",
       "2  MSPs hear renewed climate warning\\n\\nClimate c...       politics\n",
       "3  Pavey focuses on indoor success\\n\\nJo Pavey wi...          sport\n",
       "4  Tories reject rethink on axed MP\\n\\nSacked MP ...           tech"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_files\n",
    "# Loading all files in \"dir\" directory into a pandas dataframe\n",
    "DATA_DIR = \"bbc/\"\n",
    "data = load_files(DATA_DIR, encoding=\"utf-8\", decode_error=\"replace\")\n",
    "df = pd.DataFrame(list(zip(data['data'], data['target_names'])), columns=['text', 'label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder: python zip**\n",
    "- takes two lists e.g.,  ['a','b'] and [1,4] \n",
    "- returns a dictionnary with the elements of the first list as keys and of the second as values e.g.,\n",
    "{'a':1, 'b':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sravan': 23, 'ojaswi': 21, 'rohith': 32, 'gnanesh': 11, 'bobby': 23}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list with student name\n",
    "name = ['sravan', 'ojaswi', 'rohith', 'gnanesh', 'bobby']\n",
    " \n",
    "# create a list with student age\n",
    "age = [23, 21, 32, 11, 23]\n",
    " \n",
    "# using dict method with zip()\n",
    "dict(zip(name, age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting a corpus of texts into a tf-idf matrix**\n",
    "* the input is our corpus, a list of texts\n",
    "* we can specify how the text is tokenised and whether stop-words are removed\n",
    "* the output is a matrix where each row is a text and each column is a token. The cells of the matrix contain the tf-idf score of the token in that text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claire/anaconda3/envs/env803/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "corpus = ['Apples and pears are fruit','A pear is a fruit','dogs and cats are animal','a cat is an animal']\n",
    "\n",
    "from nltk import word_tokenize\n",
    "# Create a TFIDF vectorizer to convert convert words to vectors\n",
    "vectorizer = TfidfVectorizer(max_features=10,\n",
    "                                       use_idf=True,\n",
    "                                       stop_words='english',\n",
    "                                       tokenizer=nltk.word_tokenize)\n",
    "# Apply the vectorizer to the input texts\n",
    "M = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8)\n"
     ]
    }
   ],
   "source": [
    "# the output matrix contains 4 rows, one for each input document \n",
    "# and 5 columns as we set the max nb of features to 5\n",
    "print(M.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viewing the features used by the clustering algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['animal', 'apples', 'cat', 'cats', 'dogs', 'fruit', 'pear',\n",
       "       'pears'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering** \n",
    "\n",
    "[KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "* we just input the tf-idf matrix (the representation of the input texts) to a KMeans clustering model\n",
    "* the \"fit\" method fits the data i.e., aims to find the best set of clusters for it\n",
    "* n_init: the number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=2, n_init=5, random_state=3425)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=2, n_init=5, random_state=3425)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=2, n_init=5, random_state=3425)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Create a KMeans clustering model\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=5, verbose=0, random_state=3425)\n",
    "# Apply the clustering model on the tf-idf matrix (the features)\n",
    "km.fit(M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing out clustering results**\n",
    "* You can view which item belongs to which cluster using the labels_ attribute\n",
    "* If you want to use the predicted cluster labels eg for viewing (to compare with the ground truth labels) you need to explicitely store these into a list as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Print out the predicted labels\n",
    "predicted_labels = km.labels_\n",
    "print(predicted_labels)\n",
    "# Store the predicted clusters into a list\n",
    "predicted_labels = predicted_labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing clustering evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fruit', 'fruit', 'animals', 'animals']\n",
      "[1 1 0 0]\n",
      "Homogeneity: 1.000\n",
      "Completeness: 1.000\n",
      "V-measure: 1.000\n",
      "Adjusted Rand-Index: 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Show ground truth labels (if available)\n",
    "labels = [\"fruit\",\"fruit\",\"animals\",\"animals\"]\n",
    "print( labels)\n",
    "# Show predicted labels\n",
    "print( km.labels_)\n",
    "# Compute and show evaluation scores\n",
    "# When a ground truth is available\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "# When no ground truth is available\n",
    "#print(\"Silhouette Coefficient: %0.3f\"\n",
    "#      % metrics.silhouette_score(tfidf_matrix, km.labels_, sample_size=1000))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing out the number of items per clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First store documents, labels and cluster labels into a Pandas datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apples and pears are fruit</td>\n",
       "      <td>fruit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A pear is a fruit</td>\n",
       "      <td>fruit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dogs and cats are animal</td>\n",
       "      <td>animals</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a cat is an animal</td>\n",
       "      <td>animals</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text    label  cluster\n",
       "0  Apples and pears are fruit    fruit        1\n",
       "1           A pear is a fruit    fruit        1\n",
       "2    dogs and cats are animal  animals        0\n",
       "3          a cat is an animal  animals        0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'text':corpus,'label':labels,'cluster':km.labels_}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then count the number of each occurrence in the cluster column (= the number of documents for each cluster label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "1    2\n",
       "0    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the top tokens of each cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: apples fruit pear pears cats dogs cat animal\n",
      "\n",
      "Cluster 1: animal cat cats dogs apples pears pear fruit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Top terms per cluster:\")\n",
    "# get the number of clusters\n",
    "true_k = np.unique(labels).shape[0]\n",
    "\n",
    "# get the cluster center of each cluster \n",
    "# argsort() return the index of each dimension in the cluster center and sort them in increasing value order\n",
    "# [:, ::-1] reverts the argsort() list to place the indices with highest value first (decreasing order)\n",
    "order_centroids = km.cluster_centers_.argsort()[:]\n",
    "\n",
    "# terms maps a vectorizer index to the corresponding token\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# for each cluster\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    # print out the token of the centroid (order by decreasing tf-idf value)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env803",
   "language": "python",
   "name": "env803"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
