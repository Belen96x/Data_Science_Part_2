{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises Lecture 13: Topic Modeling (Gensim)\n",
    "\n",
    "In this notebook, we use LDA to perform topic modeling on a corpus of Wikipedia articles from 16 categories:\n",
    "\n",
    "Airports, Artists, Astronauts, Astronomical_objects, Building,City,Comics_characters, Companies,Foods, Monuments_and_memorials,Politicians,Sports_teams,Sportspeople, Transport, Universities_and_colleges, Written_communication..\n",
    "\n",
    "The assignment involves the following steps:\n",
    "\n",
    "* Preparing the data using Spacy, Stanza and/or NLTK \n",
    "* Training an LDA model\n",
    "* Interpreting the results of the LDA model\n",
    "   - Printing out the topk relevant tokens for each topic\n",
    "   - Computing coherence\n",
    "   - Visualising the topic graph\n",
    "\n",
    "Data: wkp_sorted.zip      \n",
    "\n",
    "Python libraries\n",
    "- sklearn.datasets to load data \n",
    "- pandas\n",
    "- WordCloud\n",
    "- gensim for topic modeling  \n",
    "\n",
    "Cheat sheets\n",
    "- clustering_cheat_sheet.ipynb   \n",
    "- topic_modeling_cheat_sheet.ipynb\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing dependent packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note\n",
    "- pyLDAvis does not work with pandas > 2.0\n",
    "- To make pyLDAvis work we need to downgrade pandas (or install pyLDAvis non stable version 3.4.1 from cloned sources)\n",
    "\n",
    "!pip3 install pandas==1.5.3   \n",
    "!pip install pyLDAvis==3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be run only once\n",
    "#!pip install gensim\n",
    "#!pip install PyLDAvis\n",
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** \n",
    "\n",
    "* Create a pandas dataframe called \"df\" containing a column with header \"text\" for the text of each Wikipedia article included in  \"wkp_sorted/\". \n",
    "* Use sklearn.datasets load_files method (cf. clustering CS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Cardiff Roller Collective (CRoC) are a rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Go! Pack Go!\" is the fight song of the Green ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al-Machriq (English translation: The East) was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ajman International Airport (Arabic: مطار عجما...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kapla is a construction set for children and a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  The Cardiff Roller Collective (CRoC) are a rol...\n",
       "1  \"Go! Pack Go!\" is the fight song of the Green ...\n",
       "2  Al-Machriq (English translation: The East) was...\n",
       "3  Ajman International Airport (Arabic: مطار عجما...\n",
       "4  Kapla is a construction set for children and a..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "# Loading all files in \"dir\" directory into a pandas dataframe\n",
    "DATA_DIR = 'wkp_sorted'\n",
    "\n",
    "data = load_files(DATA_DIR, encoding='utf-8') #Compress into a variable the whole thing THIS RETURNS A DICT. IF YOU USE CONTENT, you have the content. If you use filenames, then you got that\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': data['data']\n",
    "})\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Generate a word cloud (topic_modeling CS)\n",
    "\n",
    "* The WordCloud method takes as input the corpus as a single string. \n",
    "* Use pandas str.cat method to concatenate the content of the \"story_str\" column into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "# Join the synopses into a single string.\n",
    "#long_string = movies.str.cat(sep=\" \")\n",
    "\n",
    "long_string = df['text'].str.cat(sep=\" \")\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "# Generate a word cloud\n",
    "# YOUR CODE HERE (check the vizualisation CS)\n",
    "\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Preparing the corpus for topic modeling\n",
    "\n",
    "Gensim topic modeling module takes as input a list of tokens.\n",
    "\n",
    " - Define a clean_up function which takes as input a list of texts and outputs the list of lemmas for tokens in the input which :\n",
    "* are not stop words  \n",
    "* only contains characters (python_basic CS) \n",
    "* whose length is greater than 2\n",
    "* whose Spacy POS tag is not 'ADV','PRON','CCONJ','PUNCT','PART','DET','ADP'or 'SPACE'  or equivalent if you use Stanza or NLTK)\n",
    "\n",
    "- Apply this function to the 'text' column of the Wikipedia dataframe    \n",
    "_**Help**_ : use pandas apply method. Check linguistic preprocessing CS (NLTK, Stanza, Spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR clean_up fonction her"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply your clean_up fonction to the \"text\" column of your dataframe\n",
    "# the result should be a list of lists of tokens (each list of tokens corresonds to one of the Wikipedia files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn a topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** Create a vocabulary for the lda model and convert your list of list of lemmas into a document-term matrix\n",
    "\n",
    "* Use [Gensim dictionary method](https://radimrehurek.com/gensim/corpora/dictionary.html) to create a dictionary \n",
    "* Use Gensim doc2bow method (from Corpora module) to convert each synopsis to a list of integers\n",
    "\n",
    "**N.B.** If you did not finish Exercise 3, you can upload the cleaned up text from the clean_wkp.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (check the Topic Modeling CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** Create an LDA model with 16 topics and apply it to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (check the Topic Modeling CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** Print out the keywords of the 16 topics (Airports, Artists, Astronauts, Astronomical_objects, Building,City,Comics_characters, Companies,Foods, Monuments_and_memorials,Politicians,Sports_teams,Sportspeople, Transport, Universities_and_colleges, Written_communication)\n",
    "\n",
    "\n",
    "Each topic is a combination of keywords.\n",
    "\n",
    "* Use `lda_model.print_topics()` to see the keywords for each topic and the weight of each keyword for that topic\n",
    "* Retrain you LDA model with different numbers of topics and examine the top keywords to determine which number of topics is best\n",
    "* Can you match the topics to the Wikipedia categories ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (check the Topic Modeling CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** Compute Model Perplexity and Coherence Score\n",
    "\n",
    "* A lower perplexity score indicates better generalization performance\n",
    "* Coherence measures score a  topic by measuring the degree of semantic similarity between high scoring words in the topic.\n",
    "\n",
    "1. `C_v` measure is based on a sliding window, one-set segmentation of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity\n",
    "2. `C_p` is based on a sliding window, one-preceding segmentation of the top words and the confirmation measure of Fitelson's coherence\n",
    "3. `C_uci` measure is based on a sliding window and the pointwise mutual information (PMI) of all word pairs of the given top words\n",
    "4. `C_umass` is based on document cooccurrence counts, a one-preceding segmentation and a logarithmic conditional probability as confirmation measure\n",
    "5. `C_npmi` is an enhanced version of the C_uci coherence using the normalized pointwise mutual information (NPMI)\n",
    "6. `C_a` is based on a context window, a pairwise comparison of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (check the Topic Modeling CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the topic model using pyLDAvis (PROVIDED)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning (PROVIDED)\n",
    "\n",
    "First, let's differentiate between model hyperparameters and model parameters :\n",
    "\n",
    "- `Model hyperparameters` can be thought of as settings for a machine learning algorithm that are tuned by the data scientist before training. Examples would be the number of trees in the random forest, or in our case, number of topics K\n",
    "\n",
    "- `Model parameters` can be thought of as what the model learns during training, such as the weights for each word in a given topic.\n",
    "\n",
    "Now that we have the baseline coherence score for the default LDA model, let's perform a series of sensitivity tests to help determine the following model hyperparameters: \n",
    "- Number of Topics (K)\n",
    "- Dirichlet hyperparameter alpha: Document-Topic Density\n",
    "- Dirichlet hyperparameter beta: Word-Topic Density\n",
    "\n",
    "We'll perform these tests in sequence, one parameter at a time by keeping others constant and run them over the two difference validation corpus sets. We'll use `C_v` as our choice of metric for performance comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=doc_term_matrix,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=doc_term_matrix, dictionary=dictionary, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the function, and iterate it over the range of topics, alpha, and beta parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import gensim\n",
    "\n",
    "corpus = doc_term_matrix\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [corpus]\n",
    "\n",
    "corpus_title = ['100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=dictionary, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Training\n",
    "\n",
    "Based on external evaluation (Code to be added from Excel based analysis), train the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=16, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Perplexity\n",
    "print('Perplexity:', lda_model.log_perplexity(doc_term_matrix))\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=lemmas_list, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
